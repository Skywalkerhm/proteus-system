#!/usr/bin/env python3
"""
ğŸ§  Proteus Memory System - ä¸‰å±‚è®°å¿†æ¡†æ¶

- Working Memoryï¼ˆå·¥ä½œè®°å¿†ï¼‰ï¼šå½“å‰ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼Œä¸´æ—¶çŠ¶æ€ï¼Œä»»åŠ¡åæ¸…ç©º
- Episodic Memoryï¼ˆåœºæ™¯è®°å¿†ï¼‰ï¼šä»»åŠ¡æ‰§è¡Œè½¨è¿¹ï¼Œç”¨äºå¤ç›˜å­¦ä¹ 
- Semantic Memoryï¼ˆè¯­ä¹‰è®°å¿†ï¼‰ï¼šæ ¸å¿ƒçŸ¥è¯†åº“ï¼ŒAgent ç”»åƒã€ä»»åŠ¡æ¨¡å¼ã€è§„åˆ™åº“
"""

import json
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

class MemoryLayer:
    """è®°å¿†å±‚åŸºç±»"""
    
    def __init__(self, storage_path: Path):
        self.storage_path = storage_path
        self.storage_path.mkdir(parents=True, exist_ok=True)
    
    def save(self, key: str, data: Dict) -> str:
        raise NotImplementedError
    
    def load(self, key: str) -> Optional[Dict]:
        raise NotImplementedError
    
    def clear(self):
        raise NotImplementedError


class WorkingMemory(MemoryLayer):
    """
    å·¥ä½œè®°å¿†å±‚
    - å­˜å‚¨å½“å‰ä»»åŠ¡é“¾çš„ä¸Šä¸‹æ–‡
    - Agent é—´é€šä¿¡æ¶ˆæ¯
    - ä¸´æ—¶çŠ¶æ€
    - ä»»åŠ¡ç»“æŸåæ¸…ç©º
    """
    
    def __init__(self, storage_path: Path):
        super().__init__(storage_path)
        self.current_task_id: Optional[str] = None
        self.context: Dict[str, Any] = {}
        self.messages: List[Dict] = []
    
    def init_task(self, task_id: str, task_desc: str):
        """åˆå§‹åŒ–æ–°ä»»åŠ¡çš„å·¥ä½œè®°å¿†"""
        self.current_task_id = task_id
        self.context = {
            "task_id": task_id,
            "task_desc": task_desc,
            "created_at": datetime.now().isoformat(),
            "status": "active"
        }
        self.messages = []
        print(f"ğŸ§  [WorkingMemory] ä»»åŠ¡ {task_id[:8]} å·²åˆå§‹åŒ–")
    
    def add_message(self, sender: str, receiver: str, content: str, metadata: Dict = None):
        """è®°å½• Agent é—´é€šä¿¡"""
        msg = {
            "timestamp": datetime.now().isoformat(),
            "sender": sender,
            "receiver": receiver,
            "content": content,
            "metadata": metadata or {}
        }
        self.messages.append(msg)
    
    def update_context(self, key: str, value: Any):
        """æ›´æ–°ä¸Šä¸‹æ–‡"""
        self.context[key] = value
    
    def get_context(self, key: str = None) -> Any:
        """è·å–ä¸Šä¸‹æ–‡"""
        if key:
            return self.context.get(key)
        return self.context
    
    def clear(self):
        """æ¸…ç©ºå·¥ä½œè®°å¿†ï¼ˆä»»åŠ¡å®Œæˆåè°ƒç”¨ï¼‰"""
        task_id = self.current_task_id
        self.current_task_id = None
        self.context = {}
        self.messages = []
        print(f"ğŸ§  [WorkingMemory] ä»»åŠ¡ {task_id[:8] if task_id else 'N/A'} å·²æ¸…ç©º")
    
    def export_to_episodic(self, episodic_memory: 'EpisodicMemory'):
        """å¯¼å‡ºåˆ°åœºæ™¯è®°å¿†ï¼ˆä»»åŠ¡å®Œæˆæ—¶ï¼‰"""
        if self.current_task_id:
            episodic_data = {
                "task_id": self.current_task_id,
                "context": self.context,
                "messages": self.messages,
                "completed_at": datetime.now().isoformat()
            }
            episodic_memory.save(self.current_task_id, episodic_data)
            print(f"ğŸ§  [WorkingMemory] å·²å¯¼å‡ºåˆ°åœºæ™¯è®°å¿†")


class EpisodicMemory(MemoryLayer):
    """
    åœºæ™¯è®°å¿†å±‚
    - ä»¥ä»»åŠ¡ ID ä¸ºå•ä½å­˜å‚¨å®Œæ•´æ‰§è¡Œè½¨è¿¹
    - è®°å½•å†³ç­–ç‚¹ã€Agent è°ƒç”¨åºåˆ—ã€åä½œè®°å½•
    - ç”¨äºå¤ç›˜å’Œå­¦ä¹ 
    """
    
    def save(self, task_id: str, data: Dict) -> str:
        """ä¿å­˜ä»»åŠ¡è®°å½•"""
        filepath = self.storage_path / f"{task_id}.json"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"ğŸ§  [EpisodicMemory] ä»»åŠ¡ {task_id[:8]} å·²ä¿å­˜")
        return task_id
    
    def load(self, task_id: str) -> Optional[Dict]:
        """åŠ è½½ä»»åŠ¡è®°å½•"""
        filepath = self.storage_path / f"{task_id}.json"
        if filepath.exists():
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def list_tasks(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡ ID"""
        return [f.stem for f in self.storage_path.glob("*.json")]
    
    def get_similar_tasks(self, task_desc: str, limit: int = 5) -> List[Dict]:
        """è·å–ç›¸ä¼¼ä»»åŠ¡ï¼ˆç”¨äºæ¨¡å¼åŒ¹é…ï¼‰"""
        # TODO: å®ç°è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢
        # å½“å‰ç®€å•è¿”å›æœ€è¿‘çš„ä»»åŠ¡
        tasks = []
        for task_id in self.list_tasks()[:limit]:
            task_data = self.load(task_id)
            if task_data:
                tasks.append(task_data)
        return tasks
    
    def clear(self):
        """ä¸æ¸…ç©ºåœºæ™¯è®°å¿†ï¼ˆæ°¸ä¹…å­˜å‚¨ï¼‰"""
        pass


class SemanticMemory(MemoryLayer):
    """
    è¯­ä¹‰è®°å¿†å±‚
    - Agent èƒ½åŠ›ç”»åƒåº“
    - ä»»åŠ¡æ¨¡å¼åº“ï¼ˆSOPã€æœ€ä½³å®è·µï¼‰
    - è§„åˆ™ä¸å¯å‘å¼åº“
    """
    
    def __init__(self, storage_path: Path):
        super().__init__(storage_path)
        
        # åˆå§‹åŒ–ä¸‰ä¸ªå­åº“
        self.agents_path = self.storage_path / "agents"
        self.patterns_path = self.storage_path / "patterns"
        self.rules_path = self.storage_path / "rules"
        
        for path in [self.agents_path, self.patterns_path, self.rules_path]:
            path.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–ç´¢å¼•æ–‡ä»¶
        self._init_index("agents")
        self._init_index("patterns")
        self._init_index("rules")
    
    def _init_index(self, category: str):
        """åˆå§‹åŒ–ç´¢å¼•æ–‡ä»¶"""
        index_path = self.storage_path / f"{category}_index.json"
        if not index_path.exists():
            with open(index_path, 'w', encoding='utf-8') as f:
                json.dump([], f, ensure_ascii=False)
    
    # ========== Agent èƒ½åŠ›ç”»åƒåº“ ==========
    
    def register_agent(self, agent_id: str, profile: Dict):
        """æ³¨å†Œ/æ›´æ–° Agent ç”»åƒ"""
        profile["updated_at"] = datetime.now().isoformat()
        filepath = self.agents_path / f"{agent_id}.json"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(profile, f, indent=2, ensure_ascii=False)
        
        # æ›´æ–°ç´¢å¼•
        self._update_index("agents", agent_id)
        print(f"ğŸ§  [SemanticMemory] Agent {agent_id} å·²æ³¨å†Œ")
    
    def get_agent_profile(self, agent_id: str) -> Optional[Dict]:
        """è·å– Agent ç”»åƒ"""
        filepath = self.agents_path / f"{agent_id}.json"
        if filepath.exists():
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def match_agents(self, required_skills: List[str]) -> List[Dict]:
        """æ ¹æ®æŠ€èƒ½éœ€æ±‚åŒ¹é… Agent"""
        matched = []
        for filepath in self.agents_path.glob("*.json"):
            # è·³è¿‡ç´¢å¼•æ–‡ä»¶
            if filepath.name == "agents_index.json":
                continue
            
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    profile = json.load(f)
                    
                    # ç¡®ä¿æ˜¯å­—å…¸æ ¼å¼ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
                    if isinstance(profile, list):
                        continue
                    
                    skills = profile.get("skills", [])
                    # è®¡ç®—åŒ¹é…åº¦
                    match_score = len(set(required_skills) & set(skills)) / len(required_skills) if required_skills else 0
                    if match_score > 0:
                        matched.append((match_score, profile))
            except Exception as e:
                print(f"âš ï¸ è¯»å– Agent æ–‡ä»¶å¤±è´¥ {filepath.name}: {e}")
                continue
        
        # æŒ‰åŒ¹é…åº¦æ’åº
        matched.sort(key=lambda x: -x[0])
        return [profile for score, profile in matched]
    
    def update_agent_stats(self, agent_id: str, success: bool, execution_time: float = None):
        """æ›´æ–° Agent æ‰§è¡Œç»Ÿè®¡ï¼ˆç”¨äºè¿›åŒ–ï¼‰"""
        profile = self.get_agent_profile(agent_id)
        if profile:
            if "stats" not in profile:
                profile["stats"] = {"total": 0, "success": 0, "total_time": 0}
            
            profile["stats"]["total"] += 1
            if success:
                profile["stats"]["success"] += 1
            if execution_time:
                profile["stats"]["total_time"] += execution_time
            
            self.register_agent(agent_id, profile)
    
    # ========== ä»»åŠ¡æ¨¡å¼åº“ ==========
    
    def save_pattern(self, pattern_id: str, pattern: Dict):
        """ä¿å­˜ä»»åŠ¡æ¨¡å¼"""
        pattern["updated_at"] = datetime.now().isoformat()
        filepath = self.patterns_path / f"{pattern_id}.json"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(pattern, f, indent=2, ensure_ascii=False)
        
        self._update_index("patterns", pattern_id)
        print(f"ğŸ§  [SemanticMemory] ä»»åŠ¡æ¨¡å¼ {pattern_id} å·²ä¿å­˜")
    
    def get_pattern(self, pattern_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡æ¨¡å¼"""
        filepath = self.patterns_path / f"{pattern_id}.json"
        if filepath.exists():
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def match_pattern(self, task_desc: str) -> Optional[Dict]:
        """åŒ¹é…ç›¸ä¼¼ä»»åŠ¡æ¨¡å¼"""
        # TODO: å®ç°è¯­ä¹‰åŒ¹é…
        # å½“å‰ç®€å•è¿”å›ç¬¬ä¸€ä¸ªæ¨¡å¼
        for filepath in self.patterns_path.glob("*.json"):
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    # ========== è§„åˆ™åº“ ==========
    
    def save_rule(self, rule_id: str, rule: Dict):
        """ä¿å­˜è§„åˆ™"""
        rule["updated_at"] = datetime.now().isoformat()
        filepath = self.rules_path / f"{rule_id}.json"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(rule, f, indent=2, ensure_ascii=False)
        
        self._update_index("rules", rule_id)
        print(f"ğŸ§  [SemanticMemory] è§„åˆ™ {rule_id} å·²ä¿å­˜")
    
    def get_rule(self, rule_id: str) -> Optional[Dict]:
        """è·å–è§„åˆ™"""
        filepath = self.rules_path / f"{rule_id}.json"
        if filepath.exists():
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def get_all_rules(self) -> List[Dict]:
        """è·å–æ‰€æœ‰è§„åˆ™"""
        rules = []
        for filepath in self.rules_path.glob("*.json"):
            with open(filepath, 'r', encoding='utf-8') as f:
                rules.append(json.load(f))
        return rules
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def _update_index(self, category: str, item_id: str):
        """æ›´æ–°ç´¢å¼•"""
        index_path = self.storage_path / f"{category}_index.json"
        with open(index_path, 'r', encoding='utf-8') as f:
            index = json.load(f)
        
        if item_id not in index:
            index.append(item_id)
            with open(index_path, 'w', encoding='utf-8') as f:
                json.dump(index, f, ensure_ascii=False)
    
    def clear(self):
        """ä¸æ¸…ç©ºè¯­ä¹‰è®°å¿†ï¼ˆæ°¸ä¹…å­˜å‚¨ï¼‰"""
        pass


class MemorySystem:
    """
    ä¸‰å±‚è®°å¿†ç³»ç»Ÿæ€»æ§
    """
    
    def __init__(self, base_path: Path = None):
        if base_path is None:
            base_path = Path(__file__).parent / "memory"
        
        self.working = WorkingMemory(base_path / "working")
        self.episodic = EpisodicMemory(base_path / "episodic")
        self.semantic = SemanticMemory(base_path / "semantic")
        
        print("ğŸ§  Proteus Memory System å·²åˆå§‹åŒ–")
    
    def start_task(self, task_id: str, task_desc: str):
        """å¼€å§‹æ–°ä»»åŠ¡"""
        self.working.init_task(task_id, task_desc)
    
    def complete_task(self, success: bool, feedback: str = None):
        """å®Œæˆä»»åŠ¡"""
        # æ›´æ–°ä¸Šä¸‹æ–‡
        self.working.update_context("completed", True)
        self.working.update_context("success", success)
        if feedback:
            self.working.update_context("feedback", feedback)
        
        # å¯¼å‡ºåˆ°åœºæ™¯è®°å¿†
        self.working.export_to_episodic(self.episodic)
        
        # æ¸…ç©ºå·¥ä½œè®°å¿†
        self.working.clear()
    
    def initialize_default_agents(self):
        """åˆå§‹åŒ–é»˜è®¤ Agent ç”»åƒ"""
        agents = [
            {
                "agent_id": "research_agent",
                "name": "Research Agent",
                "emoji": "ğŸ”¬",
                "role": "ç ”ç©¶ä¸“å®¶",
                "skills": ["research", "analysis", "data_collection", "summarization"],
                "description": "æ“…é•¿ä¿¡æ¯æœé›†ã€æ•°æ®åˆ†æã€æ–‡çŒ®ç»¼è¿°",
                "stats": {"total": 0, "success": 0, "total_time": 0}
            },
            {
                "agent_id": "code_agent",
                "name": "Code Agent",
                "emoji": "ğŸ’»",
                "role": "ç¼–ç¨‹ä¸“å®¶",
                "skills": ["coding", "debugging", "testing", "architecture"],
                "description": "æ“…é•¿ä»£ç ç¼–å†™ã€è°ƒè¯•ã€æ¶æ„è®¾è®¡",
                "stats": {"total": 0, "success": 0, "total_time": 0}
            },
            {
                "agent_id": "content_agent",
                "name": "Content Agent",
                "emoji": "âœï¸",
                "role": "å†…å®¹ä¸“å®¶",
                "skills": ["writing", "editing", "copywriting", "social_media"],
                "description": "æ“…é•¿æ–‡æ¡ˆåˆ›ä½œã€å†…å®¹ç­–åˆ’ã€ç¤¾äº¤åª’ä½“è¿è¥",
                "stats": {"total": 0, "success": 0, "total_time": 0}
            },
            {
                "agent_id": "review_agent",
                "name": "Review Agent",
                "emoji": "ğŸ‘€",
                "role": "å®¡æ ¸ä¸“å®¶",
                "skills": ["review", "quality_control", "feedback", "optimization"],
                "description": "æ“…é•¿è´¨é‡å®¡æ ¸ã€åé¦ˆä¼˜åŒ–ã€é£é™©æ§åˆ¶",
                "stats": {"total": 0, "success": 0, "total_time": 0}
            }
        ]
        
        for agent in agents:
            self.semantic.register_agent(agent["agent_id"], agent)
        
        print(f"ğŸ§  å·²åˆå§‹åŒ– {len(agents)} ä¸ªé»˜è®¤ Agent")
    
    def initialize_default_rules(self):
        """åˆå§‹åŒ–é»˜è®¤è§„åˆ™"""
        rules = [
            {
                "rule_id": "collaboration_protocol",
                "name": "åä½œåè®®",
                "description": "Agent é—´é€šä¿¡å’Œåä½œçš„åŸºæœ¬è§„åˆ™",
                "content": [
                    "1. æ‰€æœ‰ Agent é€šä¿¡å¿…é¡»é€šè¿‡ Hub æˆ–åœ¨å·¥ä½œç¾¤å†…å…¬å¼€",
                    "2. é‡åˆ°éšœç¢ç«‹å³ä¸ŠæŠ¥ï¼Œä¸å¾—éšç’",
                    "3. ä»»åŠ¡å®Œæˆåå¿…é¡»æäº¤æ‰§è¡ŒæŠ¥å‘Š",
                    "4. è·¨ Agent ä¾èµ–éœ€æå‰å£°æ˜"
                ]
            },
            {
                "rule_id": "conflict_resolution",
                "name": "å†²çªè§£å†³è§„åˆ™",
                "description": "å½“ Agent é—´å‡ºç°åˆ†æ­§æ—¶çš„å¤„ç†æµç¨‹",
                "content": [
                    "1. ä¼˜å…ˆé€šè¿‡è®¨è®ºè¾¾æˆå…±è¯†",
                    "2. æ— æ³•å…±è¯†æ—¶ç”±ä¸»å¯¼ Agent å†³ç­–",
                    "3. é‡å¤§åˆ†æ­§ä¸ŠæŠ¥ Hub ä»²è£",
                    "4. æ‰€æœ‰å†²çªè®°å½•åˆ°åœºæ™¯è®°å¿†"
                ]
            },
            {
                "rule_id": "quality_standard",
                "name": "è´¨é‡æ ‡å‡†",
                "description": "ä»»åŠ¡äº¤ä»˜çš„æœ€ä½è´¨é‡è¦æ±‚",
                "content": [
                    "1. è¾“å‡ºå¿…é¡»ç»è¿‡è‡ªæ£€",
                    "2. ä»£ç å¿…é¡»æœ‰æ³¨é‡Šå’Œæµ‹è¯•",
                    "3. æ–‡æ¡ˆå¿…é¡»æ— è¯­æ³•é”™è¯¯",
                    "4. ç ”ç©¶æŠ¥å‘Šå¿…é¡»æœ‰æ•°æ®æ”¯æ’‘"
                ]
            }
        ]
        
        for rule in rules:
            self.semantic.save_rule(rule["rule_id"], rule)
        
        print(f"ğŸ§  å·²åˆå§‹åŒ– {len(rules)} ä¸ªé»˜è®¤è§„åˆ™")


if __name__ == "__main__":
    # æµ‹è¯•è®°å¿†ç³»ç»Ÿ
    memory = MemorySystem()
    
    # åˆå§‹åŒ–é»˜è®¤ Agent å’Œè§„åˆ™
    memory.initialize_default_agents()
    memory.initialize_default_rules()
    
    # æµ‹è¯•ä»»åŠ¡æµç¨‹
    task_id = str(uuid.uuid4())
    memory.start_task(task_id, "æµ‹è¯•ä»»åŠ¡")
    
    memory.working.update_context("test_key", "test_value")
    memory.working.add_message("hub", "research_agent", "è¯·æ‰§è¡Œç ”ç©¶ä»»åŠ¡")
    
    memory.complete_task(success=True, feedback="ä»»åŠ¡å®Œæˆè‰¯å¥½")
    
    print("\nâœ… è®°å¿†ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
