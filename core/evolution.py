#!/usr/bin/env python3
"""
ğŸ§¬ Proteus Evolution System - ä¸ªä½“ä¸ç¾¤ä½“è¿›åŒ–

è¿›åŒ–æœºåˆ¶ï¼š
1. ä¸ªä½“è¿›åŒ–ï¼šAgent æ ¹æ®æ‰§è¡Œå†å²æ›´æ–°èƒ½åŠ›ç”»åƒ
2. ç¾¤ä½“è¿›åŒ–ï¼šç³»ç»Ÿä»æˆåŠŸä»»åŠ¡ä¸­å‘ç°æ–°æ¨¡å¼ã€ä¼˜åŒ–è§„åˆ™
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from collections import defaultdict

class EvolutionEngine:
    """
    è¿›åŒ–å¼•æ“
    
    è´Ÿè´£åˆ†æä»»åŠ¡æ‰§è¡Œè®°å½•ï¼Œé©±åŠ¨ç³»ç»Ÿè¿›åŒ–
    """
    
    def __init__(self, memory_path: Path, evolution_path: Path):
        self.memory_path = memory_path
        self.evolution_path = evolution_path
        self.evolution_path.mkdir(parents=True, exist_ok=True)
        
        # è¿›åŒ–æ—¥å¿—
        self.evolution_log = self.evolution_path / "evolution_log.jsonl"
        
        print("ğŸ§¬ Evolution Engine å·²åˆå§‹åŒ–")
        print(f"   è®°å¿†è·¯å¾„ï¼š{memory_path}")
        print(f"   è¿›åŒ–æ—¥å¿—ï¼š{self.evolution_log}")
    
    # ========== ä¸ªä½“è¿›åŒ– ==========
    
    def evolve_agent(self, agent_id: str, task_result: Dict, semantic_memory):
        """
        ä¸ªä½“è¿›åŒ–ï¼šæ›´æ–° Agent ç”»åƒ
        
        Args:
            agent_id: Agent ID
            task_result: ä»»åŠ¡æ‰§è¡Œç»“æœ
            semantic_memory: è¯­ä¹‰è®°å¿†å¯¹è±¡
        """
        profile = semantic_memory.get_agent_profile(agent_id)
        if not profile:
            print(f"   âš ï¸  Agent {agent_id} ä¸å­˜åœ¨")
            return
        
        print(f"   ğŸ§¬ è¿›åŒ– Agent: {agent_id}")
        
        # æ›´æ–°æ‰§è¡Œç»Ÿè®¡
        if "stats" not in profile:
            profile["stats"] = {"total": 0, "success": 0, "total_time": 0}
        
        if "tasks" not in profile["stats"]:
            profile["stats"]["tasks"] = []
        
        profile["stats"]["total"] += 1
        if task_result.get("success", False):
            profile["stats"]["success"] += 1
        
        exec_time = task_result.get("execution_time", 0)
        if exec_time:
            profile["stats"]["total_time"] += exec_time
        
        # è®°å½•ä»»åŠ¡å†å²
        profile["stats"]["tasks"].append({
            "task_id": task_result.get("task_id"),
            "success": task_result.get("success", False),
            "timestamp": datetime.now().isoformat()
        })
        
        # ä¿æŒæœ€è¿‘ 50 ä¸ªä»»åŠ¡
        if len(profile["stats"]["tasks"]) > 50:
            profile["stats"]["tasks"] = profile["stats"]["tasks"][-50:]
        
        # è®¡ç®—æˆåŠŸç‡
        total = profile["stats"]["total"]
        success = profile["stats"]["success"]
        profile["stats"]["success_rate"] = round(success / total, 2) if total > 0 else 0
        
        # è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é—´
        profile["stats"]["avg_time"] = round(
            profile["stats"]["total_time"] / total, 1
        ) if total > 0 else 0
        
        # å‘ç°æ–°æŠ€èƒ½ï¼ˆä»ä»»åŠ¡ä¸­æå–ï¼‰
        new_skills = task_result.get("new_skills", [])
        if new_skills:
            current_skills = set(profile.get("skills", []))
            for skill in new_skills:
                if skill not in current_skills:
                    profile["skills"].append(skill)
                    print(f"      âœ¨ å‘ç°æ–°æŠ€èƒ½ï¼š{skill}")
        
        # æ›´æ–°åä½œåå¥½
        partners = task_result.get("collaboration_partners", [])
        if partners:
            if "preferred_partners" not in profile:
                profile["preferred_partners"] = []
            for partner in partners:
                if partner not in profile["preferred_partners"]:
                    profile["preferred_partners"].append(partner)
        
        # ä¿å­˜æ›´æ–°åçš„ç”»åƒ
        semantic_memory.register_agent(agent_id, profile)
        
        # è®°å½•è¿›åŒ–æ—¥å¿—
        self._log_evolution("agent_evolution", {
            "agent_id": agent_id,
            "success_rate": profile["stats"]["success_rate"],
            "avg_time": profile["stats"]["avg_time"],
            "total_tasks": total,
            "new_skills": new_skills
        })
        
        print(f"      æˆåŠŸç‡ï¼š{profile['stats']['success_rate']:.0%}")
        print(f"      å¹³å‡æ—¶é—´ï¼š{profile['stats']['avg_time']}min")
    
    # ========== ç¾¤ä½“è¿›åŒ– ==========
    
    def discover_patterns(self, episodic_memory, semantic_memory, min_successes: int = 3):
        """
        ç¾¤ä½“è¿›åŒ–ï¼šä»æˆåŠŸä»»åŠ¡ä¸­å‘ç°æ–°æ¨¡å¼
        
        Args:
            episodic_memory: åœºæ™¯è®°å¿†å¯¹è±¡
            semantic_memory: è¯­ä¹‰è®°å¿†å¯¹è±¡
            min_successes: æœ€å°æˆåŠŸæ¬¡æ•°
        """
        print("\nğŸ§¬ ç¾¤ä½“è¿›åŒ–ï¼šå‘ç°æ–°æ¨¡å¼")
        
        # è·å–æ‰€æœ‰æˆåŠŸä»»åŠ¡
        task_ids = episodic_memory.list_tasks()
        successful_tasks = []
        
        for task_id in task_ids:
            task_data = episodic_memory.load(task_id)
            if task_data and task_data.get("context", {}).get("success", False):
                successful_tasks.append(task_data)
        
        print(f"   æ‰¾åˆ° {len(successful_tasks)} ä¸ªæˆåŠŸä»»åŠ¡")
        
        if len(successful_tasks) < min_successes:
            print(f"   âš ï¸  æˆåŠŸä»»åŠ¡ä¸è¶³ {min_successes} ä¸ªï¼Œè·³è¿‡æ¨¡å¼å‘ç°")
            return []
        
        # åˆ†æä»»åŠ¡ç›¸ä¼¼æ€§
        patterns = self._cluster_similar_tasks(successful_tasks)
        
        new_patterns = []
        for cluster in patterns:
            if len(cluster) >= min_successes:
                pattern = self._extract_pattern(cluster)
                if pattern:
                    pattern_id = f"auto_{pattern['name'].lower().replace(' ', '_')}"
                    semantic_memory.save_pattern(pattern_id, pattern)
                    new_patterns.append(pattern)
                    print(f"      âœ¨ å‘ç°æ–°æ¨¡å¼ï¼š{pattern['name']}")
        
        # è®°å½•è¿›åŒ–æ—¥å¿—
        self._log_evolution("pattern_discovery", {
            "total_tasks": len(successful_tasks),
            "patterns_found": len(new_patterns),
            "patterns": [p["name"] for p in new_patterns]
        })
        
        return new_patterns
    
    def _cluster_similar_tasks(self, tasks: List[Dict]) -> List[List[Dict]]:
        """
        èšç±»ç›¸ä¼¼ä»»åŠ¡
        
        ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäºä»»åŠ¡æè¿°å…³é”®è¯èšç±»
        """
        clusters = defaultdict(list)
        
        for task in tasks:
            task_desc = task.get("context", {}).get("task_desc", "").lower()
            
            # ç®€å•å…³é”®è¯åˆ†ç±»
            if "ç¤¾äº¤åª’ä½“" in task_desc or "å†…å®¹" in task_desc:
                clusters["social_media"].append(task)
            elif "ç ”ç©¶" in task_desc or "æŠ¥å‘Š" in task_desc:
                clusters["research"].append(task)
            elif "ä»£ç " in task_desc or "ç¼–ç¨‹" in task_desc:
                clusters["coding"].append(task)
            else:
                clusters["generic"].append(task)
        
        return list(clusters.values())
    
    def _extract_pattern(self, tasks: List[Dict]) -> Optional[Dict]:
        """
        ä»ä»»åŠ¡ç°‡ä¸­æå–æ¨¡å¼
        """
        if not tasks:
            return None
        
        # åˆ†ææœ€å¸¸è§çš„å­ä»»åŠ¡åºåˆ—
        all_subtasks = []
        for task in tasks:
            subtasks = task.get("context", {}).get("subtasks", [])
            if subtasks:
                all_subtasks.append(subtasks)
        
        if not all_subtasks:
            return None
        
        # æå–æœ€å¸¸è§çš„å­ä»»åŠ¡ï¼ˆç®€åŒ–ï¼‰
        common_subtasks = all_subtasks[0]  # å–ç¬¬ä¸€ä¸ªä½œä¸ºæ¨¡æ¿
        
        # è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é—´
        avg_time = sum(
            st.get("estimated_time", 30)
            for st in common_subtasks
        )
        
        # æå–æ¨è Claw
        agents_used = defaultdict(int)
        for task in tasks:
            claw = task.get("context", {}).get("claw", {})
            for member in claw.get("members", []):
                agents_used[member.get("agent_id", "unknown")] += 1
        
        top_agents = sorted(agents_used.items(), key=lambda x: -x[1])[:3]
        
        # æå–æœ€ä½³å®è·µ
        best_practices = [
            "ä»»åŠ¡æ‰§è¡Œå‰æ˜ç¡®ç›®æ ‡å’ŒæˆåŠŸæ ‡å‡†",
            "å®šæœŸåŒæ­¥è¿›åº¦ï¼ŒåŠæ—¶æ²Ÿé€šéšœç¢",
            "å®Œæˆåè¿›è¡Œå¤ç›˜ï¼Œè®°å½•ç»éªŒæ•™è®­"
        ]
        
        return {
            "pattern_id": "auto_pattern",  # ä¼šè¢«è¦†ç›–
            "name": f"è‡ªåŠ¨å‘ç°çš„æ¨¡å¼-{len(tasks)} æ¬¡æˆåŠŸ",
            "description": f"ä» {len(tasks)} ä¸ªæˆåŠŸä»»åŠ¡ä¸­æå–çš„é€šç”¨æ¨¡å¼",
            "subtasks": common_subtasks,
            "recommended_claw": {
                "members": [agent_id for agent_id, _ in top_agents],
                "rationale": f"åŸºäº {len(tasks)} æ¬¡æˆåŠŸåä½œå†å²"
            },
            "best_practices": best_practices,
            "estimated_total_time": avg_time,
            "success_rate": 1.0,  # éƒ½æ˜¯æˆåŠŸä»»åŠ¡
            "sample_size": len(tasks)
        }
    
    def optimize_rules(self, episodic_memory, semantic_memory):
        """
        ä¼˜åŒ–åä½œè§„åˆ™
        
        åˆ†æå†²çªå’Œå¼‚å¸¸æƒ…å†µï¼Œæ›´æ–°è§„åˆ™åº“
        """
        print("\nğŸ§¬ ä¼˜åŒ–åä½œè§„åˆ™")
        
        # è·å–æ‰€æœ‰å¼‚å¸¸æ—¥å¿—
        exceptions = []
        for task_id in episodic_memory.list_tasks():
            task_data = episodic_memory.load(task_id)
            messages = task_data.get("messages", [])
            for msg in messages:
                if msg.get("content", "").startswith("å¼‚å¸¸") or "é”™è¯¯" in msg.get("content", ""):
                    exceptions.append({
                        "task_id": task_id,
                        "message": msg
                    })
        
        if not exceptions:
            print("   âœ… æ— å¼‚å¸¸ï¼Œè§„åˆ™è¿è¡Œè‰¯å¥½")
            return []
        
        print(f"   åˆ†æ {len(exceptions)} ä¸ªå¼‚å¸¸")
        
        # åˆ†æå¼‚å¸¸ç±»å‹ï¼ˆç®€åŒ–ï¼‰
        rule_updates = []
        
        # å¦‚æœå‘ç°æ²Ÿé€šç›¸å…³çš„å¼‚å¸¸
        communication_errors = [e for e in exceptions if "æ²Ÿé€š" in str(e)]
        if communication_errors:
            rule_updates.append({
                "rule_id": "communication_enhancement",
                "name": "æ²Ÿé€šå¢å¼ºè§„åˆ™",
                "description": "åŠ å¼º Agent é—´æ²Ÿé€šï¼Œå‡å°‘ä¿¡æ¯ä¸å¯¹ç§°",
                "content": [
                    "1. ä»»åŠ¡å¼€å§‹å‰æ˜ç¡®æœŸæœ›è¾“å‡º",
                    "2. æ‰§è¡Œä¸­æ¯ 30 åˆ†é’ŸåŒæ­¥è¿›åº¦",
                    "3. é‡åˆ°éšœç¢ç«‹å³ä¸ŠæŠ¥ï¼Œä¸è¶…è¿‡ 10 åˆ†é’Ÿ",
                    "4. ä»»åŠ¡å®Œæˆåæäº¤è¯¦ç»†æŠ¥å‘Š"
                ]
            })
        
        # ä¿å­˜æ–°è§„åˆ™
        for rule in rule_updates:
            semantic_memory.save_rule(rule["rule_id"], rule)
            print(f"      âœ¨ æ–°å¢è§„åˆ™ï¼š{rule['name']}")
        
        # è®°å½•è¿›åŒ–æ—¥å¿—
        self._log_evolution("rule_optimization", {
            "exceptions_analyzed": len(exceptions),
            "rules_added": len(rule_updates)
        })
        
        return rule_updates
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def _log_evolution(self, event_type: str, data: Dict):
        """è®°å½•è¿›åŒ–æ—¥å¿—"""
        log_entry = {
            "event": event_type,
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        with open(self.evolution_log, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    
    def get_evolution_history(self, limit: int = 10) -> List[Dict]:
        """è·å–è¿›åŒ–å†å²"""
        if not self.evolution_log.exists():
            return []
        
        history = []
        with open(self.evolution_log, 'r', encoding='utf-8') as f:
            for line in f:
                history.append(json.loads(line))
        
        return history[-limit:]


if __name__ == "__main__":
    # æµ‹è¯•è¿›åŒ–å¼•æ“
    from memory import MemorySystem
    
    memory = MemorySystem()
    engine = EvolutionEngine(
        memory_path=Path(__file__).parent.parent / "memory",
        evolution_path=Path(__file__).parent.parent / "evolution"
    )
    
    # æ¨¡æ‹Ÿä»»åŠ¡ç»“æœ
    task_result = {
        "task_id": "test_001",
        "success": True,
        "execution_time": 45,
        "new_skills": ["advanced_analysis"],
        "collaboration_partners": ["research_agent", "review_agent"]
    }
    
    # æµ‹è¯• Agent è¿›åŒ–
    print("\nğŸ§¬ æµ‹è¯• Agent è¿›åŒ–:")
    engine.evolve_agent("content_agent", task_result, memory.semantic)
    
    # æŸ¥çœ‹è¿›åŒ–å†å²
    print("\nğŸ“œ è¿›åŒ–å†å²:")
    history = engine.get_evolution_history()
    for entry in history:
        print(f"   {entry['event']}: {entry['timestamp']}")
    
    print("\nâœ… è¿›åŒ–å¼•æ“æµ‹è¯•å®Œæˆ")
